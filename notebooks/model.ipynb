{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip install numpy==1.23.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/german_credit_data.csv')\n",
    "df = df.drop(['Unnamed: 0'], axis=1)\n",
    "df.columns = [x.lower().replace(' ', '_') for x in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_dic = {\n",
    "    0: 'unskilled non res',\n",
    "    1: 'unskilled resident',\n",
    "    2: 'skilled',\n",
    "    3: 'highly skilled'\n",
    "}\n",
    "df.job = df.job.map(job_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = ['age', 'credit_amount', 'duration']\n",
    "categorical_features = ['sex', 'job', 'housing', 'saving_accounts', 'checking_account', 'purpose']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna('undefined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>job</th>\n",
       "      <th>housing</th>\n",
       "      <th>saving_accounts</th>\n",
       "      <th>checking_account</th>\n",
       "      <th>credit_amount</th>\n",
       "      <th>duration</th>\n",
       "      <th>purpose</th>\n",
       "      <th>risk</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>62</td>\n",
       "      <td>male</td>\n",
       "      <td>skilled</td>\n",
       "      <td>own</td>\n",
       "      <td>quite rich</td>\n",
       "      <td>undefined</td>\n",
       "      <td>1338</td>\n",
       "      <td>6</td>\n",
       "      <td>domestic appliances</td>\n",
       "      <td>good</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>25</td>\n",
       "      <td>male</td>\n",
       "      <td>unskilled resident</td>\n",
       "      <td>own</td>\n",
       "      <td>little</td>\n",
       "      <td>moderate</td>\n",
       "      <td>4746</td>\n",
       "      <td>45</td>\n",
       "      <td>radio/TV</td>\n",
       "      <td>bad</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>25</td>\n",
       "      <td>male</td>\n",
       "      <td>skilled</td>\n",
       "      <td>own</td>\n",
       "      <td>little</td>\n",
       "      <td>undefined</td>\n",
       "      <td>1262</td>\n",
       "      <td>12</td>\n",
       "      <td>radio/TV</td>\n",
       "      <td>good</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age   sex                 job housing saving_accounts checking_account  \\\n",
       "816   62  male             skilled     own      quite rich        undefined   \n",
       "35    25  male  unskilled resident     own          little         moderate   \n",
       "52    25  male             skilled     own          little        undefined   \n",
       "\n",
       "     credit_amount  duration              purpose  risk  target  \n",
       "816           1338         6  domestic appliances  good       0  \n",
       "35            4746        45             radio/TV   bad       1  \n",
       "52            1262        12             radio/TV  good       0  "
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'] = (df.risk == 'bad').astype(int)\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def add_columns(df):\n",
    "    df['new_column'] = df['age'] + df['sex']\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_good_and_bad_signs(df, y):\n",
    "    df['target'] = y\n",
    "    top_quantiles_space = np.linspace(.1, 0.9, 9)\n",
    "\n",
    "    numerical_frame = pd.DataFrame()\n",
    "    for feature in numerical_features:\n",
    "        for q in top_quantiles_space:\n",
    "            value = df[feature].quantile(q)\n",
    "\n",
    "            evaluation_series = (df[feature] >= value)\n",
    "            r, p = pearsonr(df.target, evaluation_series)\n",
    "            numerical_frame = pd.concat([numerical_frame, pd.DataFrame({'feature': feature, 'operation':'bigger than', 'quantile': q, 'pearsonr': r, 'value':value}, index=[0])])\n",
    "            \n",
    "            evaluation_series = (df[feature] <= value)\n",
    "            r, p = pearsonr(df.target, evaluation_series)\n",
    "            numerical_frame = pd.concat([numerical_frame, pd.DataFrame({'feature': feature, 'operation':'smaller than', 'quantile': q, 'pearsonr': r, 'value':value}, index=[0])])\n",
    "\n",
    "    categorical_frame = pd.DataFrame()\n",
    "    for feature in categorical_features:\n",
    "        for category in df[feature].unique():\n",
    "            evaluation_series = (df[feature] == category)\n",
    "            r, p = pearsonr(df.target, evaluation_series)\n",
    "            categorical_frame = pd.concat([categorical_frame, pd.DataFrame({'feature': feature, 'value': category, 'pearsonr': r}, index=[0])])\n",
    "\n",
    "    ## good_signs selection\n",
    "    numerical_bad_signs = numerical_frame[numerical_frame.pearsonr > 0.1]\n",
    "    numerical_bad_signs = numerical_bad_signs.sort_values('quantile').drop_duplicates(['feature', 'operation'], keep='first')\n",
    "    categorical_bad_signs = categorical_frame[categorical_frame.pearsonr > 0.1]\n",
    "    bad_signs = pd.concat([numerical_bad_signs, categorical_bad_signs])\n",
    "\n",
    "    numerical_good_signs = numerical_frame[numerical_frame.pearsonr < -0.1]\n",
    "    numerical_good_signs = numerical_good_signs.sort_values('quantile').drop_duplicates(['feature', 'operation'], keep='first')\n",
    "    categorical_good_signs = categorical_frame[categorical_frame.pearsonr < -0.1]\n",
    "    good_signs = pd.concat([numerical_good_signs, categorical_good_signs])\n",
    "\n",
    "    good_signs['type'] = 'good_sign'\n",
    "    bad_signs['type'] = 'bad_sign'\n",
    "\n",
    "    signs_conditions = pd.concat([good_signs, bad_signs])\n",
    "    signs_conditions = signs_conditions[['feature','operation','value', 'type']]\n",
    "    signs_conditions.operation = signs_conditions.operation.fillna('equal to')\n",
    "        \n",
    "    return signs_conditions\n",
    "\n",
    "def apply_signs_conditions(df, signs_conditions):\n",
    "    df['number_good_signs'] = 0\n",
    "    df['number_bad_signs'] = 0\n",
    "    for condition in signs_conditions.iloc:\n",
    "        sign_type = condition.type ### good or bad\n",
    "        if condition.operation == 'bigger than':\n",
    "            df[f'number_{sign_type}s'] += (df[condition.feature] >= condition.value).astype(int)\n",
    "        elif condition.operation == 'smaller than':\n",
    "            df[f'number_{sign_type}s'] += (df[condition.feature] <= condition.value).astype(int)\n",
    "        else:\n",
    "            df[f'number_{sign_type}s'] += (df[condition.feature] == condition.value).astype(int)\n",
    "            \n",
    "    df['good_bad_balance'] = df.number_good_signs - df.number_bad_signs\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_categorical_values_by_correlation(df, y):\n",
    "    df['target'] = y\n",
    "    categorical_encoder_frame = pd.DataFrame()\n",
    "    for feature in categorical_features:\n",
    "        for value in df[feature].unique():\n",
    "                evaluation_series = (df[feature] == value)\n",
    "                r, p = pearsonr(df.target, evaluation_series)\n",
    "                categorical_encoder_frame = pd.concat(\n",
    "                    [categorical_encoder_frame, pd.DataFrame(\n",
    "                        {'feature': feature, 'value': value, 'pearsonr': r}, index=[0])])\n",
    "                        \n",
    "    categorical_encoder_frame = categorical_encoder_frame.sort_values(['feature','pearsonr']\n",
    "        ).drop('pearsonr', axis=1).reset_index(drop=True)\n",
    "    categorical_encoder_frame['encoded'] = 1\n",
    "    categorical_encoder_frame.encoded = categorical_encoder_frame.groupby('feature').encoded.cumsum()\n",
    "    return categorical_encoder_frame\n",
    "\n",
    "def encode_categorical_values(df, categorical_encoder_frame):\n",
    "    for feature in categorical_features:\n",
    "        encoding_dic = categorical_encoder_frame[categorical_encoder_frame.feature == feature\n",
    "            ][['value', 'encoded']].set_index('value').to_dict()['encoded']\n",
    "        df[feature] = df[feature].map(encoding_dic)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class PreprocessingTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, dropped_features = []):\n",
    "        self.dropped_features = dropped_features\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.categorical_features_order = sort_categorical_values_by_correlation(X.copy(), y)\n",
    "        self.good_and_bad_signs_frme = find_good_and_bad_signs(X.copy(), y)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = encode_categorical_values(X.copy(), self.categorical_features_order)\n",
    "        X = apply_signs_conditions(X.copy(), self.good_and_bad_signs_frme)\n",
    "        X = X.drop(self.dropped_features, axis = 1)\n",
    "        self.features = X.columns\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "## bayes optimization\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm = lgb.LGBMClassifier(verbose = -1, n_estimators=30)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocess', PreprocessingTransformer()), ## standard scaler below\n",
    "    ('model', lgb.LGBMClassifier(verbose = -1, optimizer='dart'))\n",
    "])\n",
    "\n",
    "bayes_search = BayesSearchCV(\n",
    "    pipeline,\n",
    "    {\n",
    "        'model__num_leaves': Integer(10, 100),\n",
    "        'model__feature_fraction': Real(0.1, 1),\n",
    "        'model__learning_rate': Real(0.01, 0.1),\n",
    "    },\n",
    "    cv=5,\n",
    "    verbose=-1,\n",
    "    n_jobs=-1,\n",
    "    n_iter=3,\n",
    "    return_train_score=False\n",
    ")\n",
    "bayes_search.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(model_params, best_params):\n",
    "    for param in model_params:\n",
    "        prior = model_params[param].prior\n",
    "        if 'prior' not in ['uniform', 'log-uniform']:\n",
    "            continue\n",
    "\n",
    "        low = model_params[param].low\n",
    "        high = model_params[param].high\n",
    "\n",
    "        if prior == 'log-uniform':\n",
    "            space = np.logspace(np.log10(low), np.log10(high), 10)\n",
    "        elif prior == 'uniform':\n",
    "            space = np.linspace(low, high, 10)\n",
    "        value_found = best_params[param]\n",
    "\n",
    "        if (value_found > space[-2]) or (value_found < space[1]):\n",
    "            print('warning:', param, 'is at the edge of the search space (value:', value_found, ')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_pipeline(model, model_params, cv, n_iter, print_scores=True, dropped_features = []):\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocess', PreprocessingTransformer(dropped_features=dropped_features)), ## standard scaler below\n",
    "        ('model', model)\n",
    "        ])\n",
    "\n",
    "    bayes_search = BayesSearchCV(\n",
    "        pipeline,\n",
    "        model_params,\n",
    "        cv=cv,\n",
    "        verbose=-1,\n",
    "        n_jobs=-1,\n",
    "        return_train_score=True,\n",
    "        n_iter = n_iter\n",
    "    )\n",
    "\n",
    "    bayes_search.fit(X_train, y_train)\n",
    "\n",
    "    best_estimator_test_score = bayes_search.best_score_\n",
    "    best_estimator_train_score = bayes_search.cv_results_['mean_train_score'][bayes_search.best_index_]\n",
    "\n",
    "    output = {\n",
    "        'best_estimator_test_score': best_estimator_test_score,\n",
    "        'best_estimator_train_score': best_estimator_train_score,\n",
    "        'best_estimator': bayes_search.best_estimator_,\n",
    "        'best_params': bayes_search.best_params_\n",
    "    }\n",
    "    warn(model_params, bayes_search.best_params_)\n",
    "\n",
    "    if print_scores == True:\n",
    "        print('best estimator test score:', best_estimator_test_score)\n",
    "        print('best estimator train score:', best_estimator_train_score)\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv, n_iter = 5, 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lgbm (gradient boosting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator test score: 0.7487499999999999\n",
      "best estimator train score: 0.8034375\n"
     ]
    }
   ],
   "source": [
    "model = lgb.LGBMClassifier(verbose = -1, n_estimators=300)\n",
    "\n",
    "model_params = {\n",
    "    'model__num_leaves': Integer(10, 100, 'uniform'),\n",
    "    'model__feature_fraction': Real(0.1, 1, 'uniform'),\n",
    "    'model__learning_rate': Real(0.001, 0.1, 'log-uniform'),\n",
    "    'model__min_child_samples': Integer(5, 200, 'uniform'),\n",
    "    'model__boosting_type': Categorical(['gbdt', 'dart', 'goss']),\n",
    "    'model__n_estimators': Integer(30, 300, 'uniform'),\n",
    "}\n",
    "\n",
    "lgbm_bo = test_pipeline(model, model_params, cv, n_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lgbm (random forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator test score: 0.75125\n",
      "best estimator train score: 0.8371875\n"
     ]
    }
   ],
   "source": [
    "model = lgb.LGBMClassifier(verbose = -1, optimizer='rf', n_estimators=300)\n",
    "\n",
    "model_params = {\n",
    "    'model__num_leaves': Integer(10, 100, 'uniform'),\n",
    "    'model__feature_fraction': Real(0.1, 1, 'uniform'),\n",
    "    'model__min_child_samples': Integer(5, 200, 'uniform'),\n",
    "    'model__bagging_freq': Integer(1, 10, 'uniform'),\n",
    "    'model__bagging_fraction': Real(0.1, 1, 'uniform'),\n",
    "}\n",
    "\n",
    "lgbm_rf = test_pipeline(model, model_params, cv, n_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_estimator_test_score': 0.75125,\n",
       " 'best_estimator_train_score': 0.8371875,\n",
       " 'best_estimator': Pipeline(steps=[('preprocess', PreprocessingTransformer()),\n",
       "                 ('model',\n",
       "                  LGBMClassifier(bagging_fraction=1.0, bagging_freq=1,\n",
       "                                 feature_fraction=0.847960675218702,\n",
       "                                 min_child_samples=105, n_estimators=300,\n",
       "                                 num_leaves=43, optimizer='rf', verbose=-1))]),\n",
       " 'best_params': OrderedDict([('model__bagging_fraction', 1.0),\n",
       "              ('model__bagging_freq', 1),\n",
       "              ('model__feature_fraction', 0.847960675218702),\n",
       "              ('model__min_child_samples', 105),\n",
       "              ('model__num_leaves', 43)])}"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature importances\n",
    "importances = pd.DataFrame({'feature': lgbm_rf['best_estimator']['preprocess'].features, \n",
    "                            'importance': lgbm_rf['best_estimator']['model'].feature_importances_}\n",
    "                            ).sort_values('importance', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "todas_features = numerical_features + categorical_features + ['good_bad_balance', 'number_good_signs', 'number_bad_signs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selection_round(n_evaluations, model, model_params, todas_features, ja_removidos):\n",
    "    rows = []\n",
    "\n",
    "    todas_testadas = [x for x in todas_features if x not in ja_removidos]\n",
    "\n",
    "    for i in range(n_evaluations):\n",
    "        for tested_feature in (todas_testadas + [[]])[::-1]:\n",
    "            res = test_pipeline(model, model_params, 5, 5, dropped_features=tested_feature, print_scores=False)\n",
    "            res = (pd.DataFrame({\n",
    "                    'removed_feature': [tested_feature] + ja_removidos,\n",
    "                    'test_score': res['best_estimator_test_score']})\n",
    "                    )\n",
    "            rows.append(res)\n",
    "\n",
    "    results = pd.concat(rows).reset_index(drop=True)\n",
    "\n",
    "    results.removed_feature = results.removed_feature.astype(str)\n",
    "    results ['avg_test_score'] = results.groupby('removed_feature').test_score.transform('mean')\n",
    "    results ['std_test_score'] = results.groupby('removed_feature').test_score.transform('std')\n",
    "    results = results.sort_values('avg_test_score', ascending=False).drop_duplicates('removed_feature').reset_index(drop=True)\n",
    "    worse = results.iloc[0]\n",
    "    worse_feature = worse.removed_feature\n",
    "    worse_score = worse.avg_test_score\n",
    "    worse_std = worse.std_test_score\n",
    "\n",
    "    if worse_feature == '[]':\n",
    "        print('acabou')\n",
    "        return '[]', results\n",
    "\n",
    "    control = results[results.removed_feature == '[]'].iloc[0]\n",
    "    control_score = control.avg_test_score\n",
    "    control_std = control.std_test_score\n",
    "\n",
    "    combined_std = np.sqrt(worse_std**2 + control_std**2)\n",
    "\n",
    "    if (worse_score - control_score) < 1*combined_std:\n",
    "        print('acabou')\n",
    "        return '[]', results\n",
    "        \n",
    "    else:\n",
    "        print('removing', worse_feature)\n",
    "    return worse_feature, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removing number_good_signs\n",
      "acabou\n"
     ]
    }
   ],
   "source": [
    "n_evaluations_per_round = 4\n",
    "\n",
    "model_params = {\n",
    "    'model__feature_fraction': Real(0.8, 1, 'uniform')\n",
    "}\n",
    "model = lgb.LGBMClassifier(verbose = -1, optimizer='rf', n_estimators=100)\n",
    "\n",
    "\n",
    "ja_removidos = []\n",
    "removed = ''\n",
    "\n",
    "result = pd.DataFrame()\n",
    "while removed != '[]':\n",
    "    removed, round_res = selection_round(n_evaluations_per_round, model, model_params, todas_features[::-1], ja_removidos = ja_removidos)\n",
    "    ja_removidos.append(removed)\n",
    "    round_res['round'] = len(ja_removidos)\n",
    "    round_res['removed_feature'] = round_res.removed_feature.astype(str)\n",
    "    result = pd.concat([result, round_res])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>removed_feature</th>\n",
       "      <th>test_score</th>\n",
       "      <th>avg_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>round</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>number_good_signs</td>\n",
       "      <td>0.74125</td>\n",
       "      <td>0.741250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>number_bad_signs</td>\n",
       "      <td>0.74125</td>\n",
       "      <td>0.741250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>purpose</td>\n",
       "      <td>0.73750</td>\n",
       "      <td>0.737500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>good_bad_balance</td>\n",
       "      <td>0.73750</td>\n",
       "      <td>0.737500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "      <td>0.73125</td>\n",
       "      <td>0.731250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>saving_accounts</td>\n",
       "      <td>0.72375</td>\n",
       "      <td>0.723750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>checking_account</td>\n",
       "      <td>0.69375</td>\n",
       "      <td>0.690625</td>\n",
       "      <td>0.004419</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>number_bad_signs</td>\n",
       "      <td>0.74125</td>\n",
       "      <td>0.741250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>good_bad_balance</td>\n",
       "      <td>0.73750</td>\n",
       "      <td>0.737500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>purpose</td>\n",
       "      <td>0.73750</td>\n",
       "      <td>0.737500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[]</td>\n",
       "      <td>0.72375</td>\n",
       "      <td>0.727500</td>\n",
       "      <td>0.005303</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>number_good_signs</td>\n",
       "      <td>0.73750</td>\n",
       "      <td>0.726875</td>\n",
       "      <td>0.016809</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>saving_accounts</td>\n",
       "      <td>0.72375</td>\n",
       "      <td>0.723750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>checking_account</td>\n",
       "      <td>0.69375</td>\n",
       "      <td>0.693750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     removed_feature  test_score  avg_test_score  std_test_score  round\n",
       "0  number_good_signs     0.74125        0.741250        0.000000      1\n",
       "1   number_bad_signs     0.74125        0.741250        0.000000      1\n",
       "2            purpose     0.73750        0.737500        0.000000      1\n",
       "3   good_bad_balance     0.73750        0.737500        0.000000      1\n",
       "4                 []     0.73125        0.731250        0.000000      1\n",
       "5    saving_accounts     0.72375        0.723750        0.000000      1\n",
       "6   checking_account     0.69375        0.690625        0.004419      1\n",
       "0   number_bad_signs     0.74125        0.741250        0.000000      2\n",
       "1   good_bad_balance     0.73750        0.737500        0.000000      2\n",
       "2            purpose     0.73750        0.737500        0.000000      2\n",
       "3                 []     0.72375        0.727500        0.005303      2\n",
       "4  number_good_signs     0.73750        0.726875        0.016809      2\n",
       "5    saving_accounts     0.72375        0.723750        0.000000      2\n",
       "6   checking_account     0.69375        0.693750        0.000000      2"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
